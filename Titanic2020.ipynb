{"cells":[{"metadata":{},"cell_type":"markdown","source":"Applying the tools of ML to predict which passengers survived the tragedy:\nThe data is given by Kaggle which has been split into two groups:\n* training set (train.csv)\n* test set (test.csv)\n\nThe training set is used to build the machine learning models.\n\nThe model is based on features like passengers’ gender and class and also new features which are built using feature engineering.\n\n\nThe test set is used to see how well the models perform on unseen data. For the test set, the ground truth for each passenger is provided to predict the outcomes. For each passenger in the test set, the model predicts whether the passengers survived the sinking of the Titanic or not."},{"metadata":{},"cell_type":"markdown","source":"**Importing the Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n\n# Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Dictionary and Variable Notes**\n\n**PassengerId:**: An unique index for passenger rows. It starts from 1 for first row and increments by 1 for every new rows.\n\n**Survived:** Shows if the passenger survived or not. 1 stands for survived and 0 stands for not survived.\n\n**Pclass:** Ticket class 1 = First class ticket, 2 = Second class ticket, 3 = Third class ticket (A proxy for socio-economic status (SES) 1st = Upper, 2nd = Middle, 3rd = Lower)\n\n**Name:** Passenger's name. Name also contain title. \"Mr\" for man. \"Mrs\" for woman. \"Miss\" for girl. \"Master\" for boy.\n\n**Sex:** Passenger's sex. It's either Male or Female.\n\n**Age:** in years (\"NaN\" values in this column indicates that the age of that particular passenger has not been recorded.fractional age=1. estimated age=xx.5)\n\n**SibSp:**  Number of siblings or spouses travelling with each passenger(The dataset defines family relations in this way Sibling = brother, sister, stepbrother, stepsister Spouse = husband, wife (mistresses and fiancés were ignored))\n\n**Parch:** Number of parents of children travelling with each passenger. (The dataset defines family relations in this way  Parent = mother, father\n\nChild = daughter, son, stepdaughter, stepson  Some children travelled only with a nanny, therefore parch=0 for them)\n\n**Ticket:** Ticket number.\n\n**Fare:** How much money the passenger has paid for the travel journey.\n\n**Cabin:** Cabin number of the passenger. \"NaN\" (Not a number) values in this column indicates that the cabin number of that particular passenger has not been recorded.This missing field in  data will be filled out using feature engineering.\n\n**Embarked:** Port from where the particular passenger was embarked/boarded. First character of port name. C = Cherbourg, Q = Queenstown, S = Southampton"},{"metadata":{},"cell_type":"markdown","source":"**Loading Dataset Looking into the training dataset **"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Exploration/Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading train dataset Printing first 8 rows of the train dataset. Train is our data frame for the train dataset. To see how the train set looks like. We use head function of pandas for data frame which gives us 8 rows of training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Survived column is not present in Test data. We have to train our classifier using the Train data and generate predictions (Survived) on Test data. 11 features only missing field from the dataset is survive field which we will predict."},{"metadata":{},"cell_type":"markdown","source":"**Missing Value:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Age value is missing for many rows.\n\nOut of 891 rows, the Age value is present only in 714 rows.\n\nSimilarly, Cabin values are also missing in many rows. Only 204 out of 891 rows have Cabin values.\n\nWe use function isnull.sum it will give the number of null data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 177 rows with missing Age, 687 rows with missing Cabin and 2 rows with missing Embarked information."},{"metadata":{},"cell_type":"markdown","source":"**Relationship between Features and Survival**\n\nWe analyze relationship between different features with respect to Survival. We see how different feature values show different survival chance using different kinds of diagrams to visualize our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"survived = train[train['Survived'] == 1]\nnot_survived = train[train['Survived'] == 0]\n\nprint (\"Survived: %i (%.1f%%)\"%(len(survived), float(len(survived))/len(train)*100.0))\nprint (\"Not Survived: %i (%.1f%%)\"%(len(not_survived), float(len(not_survived))/len(train)*100.0))\nprint (\"Total: %i\"%len(train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pclass vs. Survival**\n\nHigher class passengers have better survival chance.\n\nTotal number of passengers in each passenger class."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Pclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of survived and unsurvived passengers in each passenger class."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Pclass').Survived.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Pclass', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sex vs. Survival**\n\nFemales have better survival chance."},{"metadata":{},"cell_type":"markdown","source":"Total number of female and male passengers"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Sex.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.groupby('Sex').Survived.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Sex', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"women = train.loc[train.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"men = train.loc[train.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pclass & Sex vs. Survival**\n\nThe number of males and females in each Pclass have been shown.\nIn the diagram we found that there are more males among the 3rd Pclass passengers."},{"metadata":{"trusted":true},"cell_type":"code","source":"tab = pd.crosstab(train['Pclass'], train['Sex'])\nprint (tab)\n\ntab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.xlabel('Pclass')\nplt.ylabel('Percentage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot('Sex', 'Survived', hue='Pclass', size=4, aspect=2, data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above plot shows that:\n\nWomen from 1st and 2nd Pclass have almost 100% survival chance. \n\nMen from 2nd and 3rd Pclass have only around 10% survival chance."},{"metadata":{},"cell_type":"markdown","source":"**Pclass, Sex & Embarked vs. Survival**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x='Pclass', y='Survived', hue='Sex', col='Embarked', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plot, it can be seen that:\n\nAlmost all females from Pclass 1 and 2 survived.\n\nFemales dying were mostly from 3rd Pclass.\n\nMales from Pclass 1 only have slightly higher survival chance than Pclass 2 and 3"},{"metadata":{},"cell_type":"markdown","source":"**Embarked vs. Survived**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Embarked').Survived.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Embarked', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Parch vs. Survival**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Parch.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Parch').Survived.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Parch', y='Survived', ci=None, data=train)","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sns' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c76095fc8e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Parch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"**SibSp vs. Survival**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.SibSp.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('SibSp').Survived.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='SibSp', y='Survived', ci=None, data=train) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Required Data and Feature Engineering:**\n\nWe need to convert a lot of features into numeric ones.\n\nFeatures have different ranges,we will put them into the same scale.\n\nSome features contain missing values (NaN = not a number)\n\nBy doing that features(columns) will be more understandable by Machine Learning algorithm."},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing and Feature Selection**\n\nUnecessary columns/features are dropped and keep only the useful ones. Column PassengerId is only dropped from Train set because we need PassengerId in Test set to be submitted."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['PassengerId'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cabin:**\nWe extract from the cabin number the deck and create new feature and then we convert them to numeric value."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndeck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\ndata = [train, test]\n\nfor dataset in data:\n    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    dataset['Deck'] = dataset['Deck'].map(deck)\n    dataset['Deck'] = dataset['Deck'].fillna(0)\n    dataset['Deck'] = dataset['Deck'].astype(int)\n\ntrain = train.drop(['Cabin'], axis=1)\ntest = test.drop(['Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Age:**\n\nWe fill the Null values of age with a random number between (mean_age-std_age) and (mean_age+std_age)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\n\nfor dataset in data:\n    mean = train[\"Age\"].mean()\n    std = test[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    \n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    \n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = train[\"Age\"].astype(int)\ntrain[\"Age\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Embarked:**\n\nThere are 2 empty values for Embarked column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of passengers for each Embarked category"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Category \"S\" has maxomum passengers. So we replace \"NaN\" value with \"S\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"common_value = 'S'\ndata = [train, test]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting Features:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fare:**\n\nWe convert “Fare” from float to int64, using the “astype()” function pandas provides:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\n\nfor dataset in data:\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Fare'] = dataset['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Name:**\n\nWe extract Titles from the Name."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\nfor dataset in data:\n   \n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n   \n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \n    dataset['Title'] = dataset['Title'].map(titles)\n   \n    dataset['Title'] = dataset['Title'].fillna(0)\ntrain = train.drop(['Name'], axis=1)\ntest = test.drop(['Name'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sex:**\n\nHere Sex value is converted to 0 and 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"genders = {\"male\": 0, \"female\": 1}\ndata = [train, test]\n\nfor dataset in data:\n    dataset['Sex'] = dataset['Sex'].map(genders)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ticket:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Ticket'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We  drop ticket from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['Ticket'], axis=1)\ntest = test.drop(['Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Embarked:**\n\nHere we convert‘Embarked’ feature into numeric."},{"metadata":{"trusted":true},"cell_type":"code","source":"ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\ndata = [train, test]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].map(ports)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**features Categories:**"},{"metadata":{},"cell_type":"markdown","source":"**Age**:\n\nWe convert age from float into integer.We create \"AgeGroup” variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n\ntrain['Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fair**\nHere we put fair in groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\n\nfor dataset in data:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n    dataset['Fare'] = dataset['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating new Features**"},{"metadata":{},"cell_type":"markdown","source":"**Age_Class**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\nfor dataset in data:\n    dataset['Age_Class']= dataset['Age']* dataset['Pclass']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fare per Person**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [train, test]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n    dataset['not_alone'] = dataset['not_alone'].astype(int)\ntrain['not_alone'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in data:\n    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building Machine Learning Models**\nWe build multiple classifier to predict our dataset and compare their results. We need to use the predictions on the training set to compare the algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Stochastic Gradient Descent (SGD):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\n\nsgd.score(X_train, Y_train)\n\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_prediction = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K Nearest Neighbor:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3) \nknn.fit(X_train, Y_train)  \nY_pred = knn.predict(X_test) \nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gaussian Naive Bayes:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gaussian = GaussianNB() \ngaussian.fit(X_train, Y_train)  \nY_pred = gaussian.predict(X_test)  \nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Perceptron:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"perceptron = Perceptron(max_iter=5)\nperceptron.fit(X_train, Y_train)\n\nY_pred = perceptron.predict(X_test)\n\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Support Vector Machine:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\n\nY_pred = linear_svc.predict(X_test)\n\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)  \nY_pred = decision_tree.predict(X_test)  \nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparng accuracy rate of models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', \n              'Decision Tree'],\n    'Score': [acc_linear_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_decision_tree]})\nresult = results.sort_values(by='Score', ascending=False)\nresult = result.set_index('Score')\nresult.head(9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Fold Cross Validation:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nrf = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance**\n\nNow we compare importance of each feature by looking at how much the tree nodes reduce impurity on average across all trees in the forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"not_alone and Parch are less important so we drop them."},{"metadata":{"trusted":true},"cell_type":"code","source":"train  = train.drop(\"not_alone\", axis=1)\ntest  = test.drop(\"not_alone\", axis=1)\n\ntrain  = train.drop(\"Parch\", axis=1)\ntest  = test.drop(\"Parch\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reraining random forest:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\nrandom_forest.fit(X_train, Y_train)\nY_prediction = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\n\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nprint(round(acc_random_forest,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n    \"PassengerId\":test[\"PassengerId\"],\n    \"Survived\":Y_prediction\n})\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result and Conclusions**\n\nIn this project first the data has been explored the missing data processed and important features have been found.During the data preprocessing part, missing values have been computed, features have been converted into numeric ones, values grouped and categories and new features have been created. \nDifferent methods have been tested on this database and after comparing the result the  Decision Tree and Random Forest have the most accurate result.\nAt the end random forest has been chosen because it has the ability to limit overfitting as compared to Decision Tree classifier and cross validation has been applied on it.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}